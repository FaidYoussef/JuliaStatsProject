{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement des données\n",
    "Dans cette section, nous allons charger les données à partir d'un fichier Excel. Nous utiliserons la bibliothèque `ExcelReaders` pour lire le fichier et la bibliothèque `DataFrames` pour manipuler les données.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DataFrames\n",
    "using ExcelReaders\n",
    "using Plots\n",
    "using DataValues\n",
    "using XLSX\n",
    "using Statistics\n",
    "using Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette section, nous chargeons les données à partir des fichier Excel `IND-COL-1.xls` et `IND-COL-2.xls` situé dans le répertoire spécifié."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_matrix_ind_col1 = readxlsheet(\"/home/AD/faidy/JuliaStatsProject/data/raw/real_data/Données_EDF_240611/Colmatage/IND-COL-1.xls\", \"IND-COL-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_matrix_ind_col2 = readxlsheet(\"/home/AD/faidy/JuliaStatsProject/data/raw/real_data/Données_EDF_240611/Colmatage/IND-COL-2.xls\", \"IND-COL-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typeof(data_matrix_ind_col1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isNA(x) = typeof(x) == DataValue{Union{}}\n",
    "valeurs = replace( x -> isNA(x) ? missing : x, data_matrix_ind_col1)\n",
    "\n",
    "data_matrix_ind_col1 = replace( x -> isNA(x) ? missing : x, data_matrix_ind_col1)\n",
    "data_matrix_ind_col2 = replace( x -> isNA(x) ? missing : x, data_matrix_ind_col2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion de Matrice en DataFrame\n",
    "\n",
    "La fonction `MatrixToDataFrame(mat)` prend en entrée une matrice `mat` et retourne un DataFrame `DF_mat` en excluant la première ligne de `mat` comme les noms de colonnes.\n",
    "\n",
    "#### Paramètres :\n",
    "\n",
    "- `mat` : Une matrice représentant les données à convertir en DataFrame.\n",
    "\n",
    "#### Sortie :\n",
    "\n",
    "Un objet DataFrame `DF_mat` où les données de la première ligne de `mat` sont utilisées comme noms de colonnes.\n",
    "\n",
    "Cette fonction est utile pour convertir des données structurées sous forme de matrice en un format plus facile à manipuler et à analyser à l'aide de la bibliothèque `DataFrames` en Julia.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function MatrixToDataFrame(mat)\n",
    "    DF_mat = DataFrame(\n",
    "        mat[2:end, 1:end],\n",
    "        string.(mat[1, 1:end])\n",
    "    )\n",
    "    return DF_mat\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = MatrixToDataFrame(data_matrix_ind_col1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = MatrixToDataFrame(data_matrix_ind_col2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typeof(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suppression des valeurs manquantes\n",
    "\n",
    "Les lignes suivantes suppriment les lignes de `df1` et `df2` où la colonne `:VALEUR` contient des valeurs manquantes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = dropmissing(df1, :VALEUR)\n",
    "df2 = dropmissing(df2, :VALEUR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fusion de deux DataFrames\n",
    "\n",
    "La ligne suivante fusionne les DataFrames `df1` et `df2` en un seul DataFrame `df_one_two`, en ajoutant les colonnes de manière à inclure toutes les colonnes présentes dans les deux DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_one_two = vcat(df1, df2, cols = :union )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement et prétraitement des données de nettoyages\n",
    "\n",
    "Les lignes suivantes chargent les données à partir du fichier Excel \"NETTOYAGES.xls\" et effectuent plusieurs étapes de prétraitement pour obtenir un DataFrame `df_nettoyages` bien structuré."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nettoyages = readxlsheet(\"/home/AD/faidy/JuliaStatsProject/data/raw/real_data/Données_EDF_240611/Nettoyages/NETTOYAGES.xls\", \"NETTOYAGES\")\n",
    "df_nettoyages = MatrixToDataFrame(nettoyages)\n",
    "df_nettoyages = df_nettoyages[:, [:UNITE, :SOUS_UNITE, :CIRCUIT, :NUMERO, :HEURES_MAT]]\n",
    "df_nettoyages = rename!(df_nettoyages, :HEURES_MAT => :HEURES_NETT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prétraitement des DataFrames pour gérer la permutation\n",
    "\n",
    "La fonction suivante, `preprocess_data!`, prend en entrée un DataFrame `df` et effectue un traitement spécifique pour gérer les permutations de lignes selon certaines conditions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data frames to handle the permutation\n",
    "function preprocess_data!(df)\n",
    "    i = 1\n",
    "    while i < nrow(df)\n",
    "        if df.APRES_NET[i] == 1 && df.AVANT_NET[i + 1] == 1\n",
    "            # Permute the rows\n",
    "            df[i, :], df[i + 1, :] = df[i + 1, :], df[i, :]\n",
    "            i += 1  # Skip the next row as it was just swapped\n",
    "        end\n",
    "        i += 1\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation conditionnelle des données IND-COL-1 et IND-COL-2\n",
    "\n",
    "Le bloc de code suivant effectue une analyse et une visualisation conditionnelles des données IND-COL-1 et IND-COL-2 pour différentes unités et sous-unités, en tenant compte des temps de nettoyage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_one_two = df_one_two[:, [:HEURES_MAT, :VALEUR, :AVANT_NET, :APRES_NET, :UNITE, :SOUS_UNITE, :CIRCUIT, :NUMERO, :BR, :PE, :SONDE]]\n",
    "unites = unique(df_one_two.UNITE)\n",
    "\n",
    "nbE9 = 0\n",
    "nbE8 = 0\n",
    "\n",
    "for unite in unites\n",
    "    unite_data = df_one_two[df_one_two.UNITE .== unite, :]\n",
    "    sous_unites = unique(unite_data.SOUS_UNITE)\n",
    "    \n",
    "    for sous_unite in sous_unites\n",
    "        sous_unite_data = unite_data[unite_data.SOUS_UNITE .== sous_unite, :]\n",
    "        \n",
    "        # Initialize arrays to store combined data for all circuits within a sous_unite\n",
    "        combined_ind_col_1_C = Vector{DataFrame}()\n",
    "        combined_ind_col_2_C = Vector{DataFrame}()\n",
    "        combined_ind_col_1_F = Vector{DataFrame}()\n",
    "        combined_ind_col_2_F = Vector{DataFrame}()\n",
    "        \n",
    "        circuits = unique(sous_unite_data.CIRCUIT)\n",
    "        \n",
    "        PE = \"E9\"\n",
    "        for circuit in circuits\n",
    "            circuit_data_C = filter(row -> row.PE .== \"E9\" && row.BR .== \"C\", sous_unite_data[sous_unite_data.CIRCUIT .== circuit, :])\n",
    "            circuit_data_F = filter(row -> row.PE .== \"E9\" && row.BR .== \"F\", sous_unite_data[sous_unite_data.CIRCUIT .== circuit, :])\n",
    "            nbE9 += 1\n",
    "            if isempty(circuit_data_C)\n",
    "                circuit_data_C = filter(row -> row.PE .== \"E8\" && row.BR .== \"C\", sous_unite_data[sous_unite_data.CIRCUIT .== circuit, :])\n",
    "                circuit_data_F = filter(row -> row.PE .== \"E8\" && row.BR .== \"F\", sous_unite_data[sous_unite_data.CIRCUIT .== circuit, :])\n",
    "                nbE9 -= 1\n",
    "                nbE8 += 1\n",
    "                PE = \"E8\"\n",
    "            end\n",
    "            \n",
    "            ind_col_1_C = circuit_data_C[ismissing.(circuit_data_C.SONDE), :]\n",
    "            ind_col_1_F = circuit_data_F[ismissing.(circuit_data_F.SONDE), :]\n",
    "            sort!(ind_col_1_C, :HEURES_MAT)\n",
    "            sort!(ind_col_1_F, :HEURES_MAT)\n",
    "            ind_col_2_C = circuit_data_C[.!ismissing.(circuit_data_C.SONDE), :]\n",
    "            ind_col_2_F = circuit_data_F[.!ismissing.(circuit_data_F.SONDE), :]\n",
    "            sort!(ind_col_2_C, :HEURES_MAT)\n",
    "            sort!(ind_col_2_F, :HEURES_MAT)\n",
    "            \n",
    "            # Append data to the combined arrays\n",
    "            push!(combined_ind_col_1_C, ind_col_1_C)\n",
    "            push!(combined_ind_col_1_F, ind_col_1_F)\n",
    "            push!(combined_ind_col_2_C, ind_col_2_C)\n",
    "            push!(combined_ind_col_2_F, ind_col_2_F)\n",
    "        end\n",
    "        \n",
    "        heures_nettoyages = filter(row -> row.UNITE .== unite && row.SOUS_UNITE .== sous_unite, df_nettoyages)\n",
    "        \n",
    "        if !isempty(heures_nettoyages)\n",
    "            nettoyage_times = unique(heures_nettoyages[:,:HEURES_NETT])\n",
    "\n",
    "            has_points_between_nettoyages_1 = true\n",
    "            for i in 1:length(nettoyage_times) - 1\n",
    "                for df in combined_ind_col_1_C\n",
    "                    if !any((df.HEURES_MAT .> nettoyage_times[i]) .& (df.HEURES_MAT .< nettoyage_times[i + 1]))\n",
    "                        has_points_between_nettoyages_1 = false\n",
    "                        break\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "            \n",
    "            has_points_between_nettoyages_2 = true\n",
    "            for i in 1:length(nettoyage_times) - 1\n",
    "                for df in combined_ind_col_2_C\n",
    "                    if !any((df.HEURES_MAT .> nettoyage_times[i]) .& (df.HEURES_MAT .< nettoyage_times[i + 1]))\n",
    "                        has_points_between_nettoyages_2 = false\n",
    "                        break\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "            \n",
    "            if has_points_between_nettoyages_1 || has_points_between_nettoyages_2\n",
    "                p = plot(\n",
    "                    xlabel=\"HEURES_MAT\", \n",
    "                    ylabel=\"VALEUR\", \n",
    "                    title=\"Évolution de IND-COL-1 et IND-COL-2 sur le(s) GV de $unite-$sous_unite de PE=$PE\", \n",
    "                    titlefont=10\n",
    "                    )\n",
    "                \n",
    "                # Apply preprocessing to combined_ind_col_1 and combined_ind_col_2\n",
    "                for df in combined_ind_col_1_C\n",
    "                    preprocess_data!(df)\n",
    "                end\n",
    "\n",
    "                for df in combined_ind_col_2_C\n",
    "                    preprocess_data!(df)\n",
    "                end\n",
    "\n",
    "                for df in combined_ind_col_1_F\n",
    "                    preprocess_data!(df)\n",
    "                end\n",
    "\n",
    "                for df in combined_ind_col_2_F\n",
    "                    preprocess_data!(df)\n",
    "                end\n",
    "\n",
    "                for df in combined_ind_col_1_C\n",
    "                    # Trace IND-COL-1 segments conditionnellement\n",
    "                    for i in 1:length(df.HEURES_MAT) - 1\n",
    "                        if !(df.AVANT_NET[i] || df.APRES_NET[i + 1] || any((nettoyage_times .> df.HEURES_MAT[i]) .& (nettoyage_times .< df.HEURES_MAT[i + 1])))\n",
    "                            plot!(p, df.HEURES_MAT[i:i + 1], df.VALEUR[i:i + 1], label=false, color=:yellow, linestyle=:dash)\n",
    "                        end\n",
    "                    end\n",
    "                end\n",
    "\n",
    "                for df in combined_ind_col_2_C\n",
    "                    # Trace IND-COL-2 segments conditionnellement\n",
    "                    for i in 1:length(df.HEURES_MAT) - 1\n",
    "                        if !(df.AVANT_NET[i] || df.APRES_NET[i + 1] || any((nettoyage_times .> df.HEURES_MAT[i]) .& (nettoyage_times .< df.HEURES_MAT[i + 1])))\n",
    "                            plot!(p, df.HEURES_MAT[i:i + 1], df.VALEUR[i:i + 1], label=false, color=:red, linestyle=:dash)\n",
    "                        end\n",
    "                    end\n",
    "                end\n",
    "                \n",
    "                a = true\n",
    "\n",
    "                for df in combined_ind_col_1_C\n",
    "                    # Trace les points\n",
    "                    scatter!(p, df.HEURES_MAT, df.VALEUR, markershape=:circle, label=a ? \"1-C\" : false, markercolor=:yellow)\n",
    "                    a = false\n",
    "                end\n",
    "\n",
    "                a = true\n",
    "\n",
    "                for df in combined_ind_col_2_C\n",
    "                    scatter!(p, df.HEURES_MAT, df.VALEUR, markershape=:diamond, label=a ? \"2-C\" : false, markercolor=:red)\n",
    "                    a = false\n",
    "                end\n",
    "\n",
    "                \n",
    "                for df in combined_ind_col_1_F\n",
    "                    # Trace IND-COL-1 segments conditionnellement\n",
    "                    for i in 1:length(df.HEURES_MAT) - 1\n",
    "                        if !(df.AVANT_NET[i] || df.APRES_NET[i + 1] || any((nettoyage_times .> df.HEURES_MAT[i]) .& (nettoyage_times .< df.HEURES_MAT[i + 1])))\n",
    "                            plot!(p, df.HEURES_MAT[i:i + 1], df.VALEUR[i:i + 1], label=false, color=:green, linestyle=:dash)\n",
    "                        end\n",
    "                    end\n",
    "                end\n",
    "                \n",
    "                for df in combined_ind_col_2_F\n",
    "                    # Trace IND-COL-2 segments conditionnellement\n",
    "                    for i in 1:length(df.HEURES_MAT) - 1\n",
    "                        if !(df.AVANT_NET[i] || df.APRES_NET[i + 1] || any((nettoyage_times .> df.HEURES_MAT[i]) .& (nettoyage_times .< df.HEURES_MAT[i + 1])))\n",
    "                        plot!(p, df.HEURES_MAT[i:i + 1], df.VALEUR[i:i + 1], label=false, color=:blue, linestyle=:dash)\n",
    "                        end\n",
    "                    end\n",
    "                end\n",
    "                \n",
    "                a = true\n",
    "                for df in combined_ind_col_1_F\n",
    "                    # Trace les points\n",
    "                    scatter!(p, df.HEURES_MAT, df.VALEUR, markershape=:circle, label=a ? \"1-F\" : false, markercolor=:green)\n",
    "                    a = false\n",
    "                end\n",
    "\n",
    "                a = true\n",
    "                for df in combined_ind_col_2_F\n",
    "                    scatter!(p, df.HEURES_MAT, df.VALEUR, markershape=:diamond, label=a ? \"2-F\" : false, markercolor=:blue)\n",
    "                    a = false\n",
    "                end\n",
    "                \n",
    "                # Trace des lignes verticales pour les temps de nettoyage\n",
    "                vline!(p, nettoyage_times, linestyle=:dot, color=:black, linewidth=1.5, label=false)\n",
    "                \n",
    "                # Chemin du répertoire où vous souhaitez enregistrer le fichier (relatif au répertoire de travail actuel)\n",
    "                directory = \"/home/AD/faidy/JuliaStatsProject/plots/IND-COL-1-2\"\n",
    "                \n",
    "                # Combiner le chemin de répertoire et le nom du fichier\n",
    "                filename = joinpath(directory, \"IND-COL-1&2 $unite $sous_unite.png\")\n",
    "                \n",
    "                # Sauvegarder le graphique dans le fichier spécifié\n",
    "                savefig(p, filename)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nombre de sous unités pour chaque unité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DataFrames\n",
    "\n",
    "# Supposons que df_one_two est déjà chargé\n",
    "\n",
    "# Obtenir toutes les unités uniques\n",
    "unites = unique(df_one_two.UNITE)\n",
    "\n",
    "# Initialiser un dictionnaire pour stocker le nombre de sous-unités par unité\n",
    "nombre_sous_unites = Dict{String, Int}()\n",
    "\n",
    "# Boucle sur chaque unité unique\n",
    "for unite in unites\n",
    "    # Filtrer les données pour l'unité spécifique\n",
    "    unite_data = df_one_two[df_one_two.UNITE .== unite, :]\n",
    "    \n",
    "    # Obtenir toutes les sous-unités uniques pour cette unité\n",
    "    sous_unites = unique(unite_data.SOUS_UNITE)\n",
    "    \n",
    "    # Calculer le nombre de sous-unités\n",
    "    num_sous_unites = length(sous_unites)\n",
    "    \n",
    "    # Stocker le résultat dans le dictionnaire\n",
    "    nombre_sous_unites[unite] = num_sous_unites\n",
    "end\n",
    "\n",
    "\n",
    "# Convertir nombre_sous_unites en DataFrame pour faciliter la visualisation\n",
    "df_nb_sous_unites = DataFrame(UNITE = collect(keys(nombre_sous_unites)), Nombre_de_sous_unites = collect(values(nombre_sous_unites)))\n",
    "\n",
    "# Trier par ordre décroissant du nombre de sous-unités\n",
    "sort!(df_nb_sous_unites, :Nombre_de_sous_unites, rev=true)\n",
    "\n",
    "# Afficher un bar plot\n",
    "bar(df_nb_sous_unites.UNITE, df_nb_sous_unites.Nombre_de_sous_unites, \n",
    "    xlabel = \"Unité\", \n",
    "    ylabel = \"Nombre de sous-unités\",\n",
    "    title = \"Nombre de sous-unités par unité\",\n",
    "    legend = false,\n",
    "    fmt=:png)  # Format de l'image\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nombre de graphe avec E9 / E8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(\" % E8 : \", nbE8/(nbE8 + nbE9))\n",
    "println(\" % E9 : \", nbE9/(nbE8 + nbE9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Génération du fichier points aberrants.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DataFrames\n",
    "using Plots\n",
    "\n",
    "# Supposons que df_one_two est déjà chargé\n",
    "\n",
    "# Créer un DataFrame pour stocker les résultats\n",
    "df_nombre_circuits = DataFrame(UNITE = String[], SOUS_UNITE = String[], Nombre_de_circuits = Int[])\n",
    "\n",
    "# Group by sur (UNITE, SOUS_UNITE) et calcul du nombre de circuits uniques\n",
    "for group in groupby(df_one_two, [:UNITE, :SOUS_UNITE])\n",
    "    unite = group[!, :UNITE][1]\n",
    "    sous_unite = group[!, :SOUS_UNITE][1]\n",
    "    nombre_circuits = unique(group[!, :CIRCUIT])\n",
    "    push!(df_nombre_circuits, (unite, sous_unite, nombre_circuits))\n",
    "    break\n",
    "end\n",
    "\n",
    "# Trier par ordre décroissant du nombre de circuits\n",
    "sort!(df_nombre_circuits, :Nombre_de_circuits, rev=true)\n",
    "\n",
    "# Affichage des résultats\n",
    "println(df_nombre_circuits)\n",
    "\n",
    "# Optionnel : Création d'un graphique à barres avec Plots.jl\n",
    "p = bar(df_nombre_circuits.UNITE .* \" - \" .* df_nombre_circuits.SOUS_UNITE, df_nombre_circuits.Nombre_de_circuits,\n",
    "        xlabel = \"Unité - Sous-unité\",\n",
    "        ylabel = \"Nombre de circuits\",\n",
    "        title = \"Nombre de circuits par couple (unité, sous-unité)\",\n",
    "        legend = false,\n",
    "        xrotation = 45,  # Rotation des étiquettes sur l'axe des x\n",
    "        fmt=:png)  # Format de l'image\n",
    "\n",
    "# Enregistrer l'image du plot\n",
    "savefig(\"bar_plot_nombre_circuits.png\")\n",
    "\n",
    "println(\"Le bar plot a été sauvegardé sous le nom 'bar_plot_nombre_circuits.png'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize an empty list to store the counts\n",
    "nb_heures_nett = []\n",
    "\n",
    "# Store labels for plotting\n",
    "labels = []\n",
    "\n",
    "unites = unique(df_nettoyages.UNITE)\n",
    "\n",
    "for unite in unites\n",
    "    unite_data = df_nettoyages[df_nettoyages.UNITE .== unite, :]\n",
    "    sous_unites = unique(unite_data.SOUS_UNITE)\n",
    "    \n",
    "    for sous_unite in sous_unites\n",
    "        sous_unite_data = unite_data[unite_data.SOUS_UNITE .== sous_unite, :]\n",
    "        unique_hours = unique(sous_unite_data.HEURES_NETT)\n",
    "        push!(nb_heures_nett, length(unique_hours))\n",
    "        push!(labels, \"$unite-$sous_unite\")\n",
    "    end\n",
    "end\n",
    "# Convert the counts and labels to arrays for plotting\n",
    "nb_heures_nett_array = collect(nb_heures_nett)\n",
    "labels_array = collect(labels)\n",
    "# Define the positions for the x-ticks\n",
    "positions = 1:length(labels_array)\n",
    "# Create the bar plot\n",
    "bar(labels_array, nb_heures_nett_array, \n",
    "    xlabel=\"Unite-Sous_Unite\", \n",
    "    ylabel=\"Number of Unique HEURES_NETT\", \n",
    "    title=\"Unique HEURES_NETT per Unite-Sous_Unite\", \n",
    "    legend=false, \n",
    "    rotation=90, \n",
    "    size=(900, 400), \n",
    "    xguidefont=font(8),\n",
    "    xticks=(positions, labels_array))  # Specify positions and labels\n",
    "hline!([mean(nb_heures_nett_array)], color=:red, linestyle=:dash, linewidth=2, label=\"Mean Value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DataFrames\n",
    "\n",
    "# Supposons que df_nettoyages et df_one_two sont déjà chargés\n",
    "\n",
    "# Filtrer df_one_two pour APRES_NET = 0 et AVANT_NET = 0\n",
    "filtered_df_one_two = filter(row -> row.APRES_NET == 0 && row.AVANT_NET == 0  && !ismissing(row.SONDE), df_one_two)\n",
    "\n",
    "df_n = df_nettoyages\n",
    "rename!(df_n, :HEURES_NETT => :HEURES_MAT)\n",
    "\n",
    "# Effectuer la jointure\n",
    "joined_df = innerjoin(filtered_df_one_two, df_n, on = [:UNITE, :SOUS_UNITE, :CIRCUIT, :NUMERO, :HEURES_MAT])\n",
    "\n",
    "# Compter le nombre de lignes dans le résultat de la jointure\n",
    "nombre_de_points = nrow(joined_df)\n",
    "\n",
    "println(\"Le nombre de points est: \", nombre_de_points)\n",
    "joined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DataFrames\n",
    "\n",
    "\n",
    "# Filtrer df_one_two pour APRES_NET = 0, AVANT_NET = 0 et SONDE = \"IND-COL-2\"\n",
    "filtered_df_one_two = filter(row -> row.APRES_NET == 0 && row.AVANT_NET == 0 && !ismissing(row.SONDE), df_one_two)\n",
    "\n",
    "# Grouper les données filtrées par les colonnes spécifiques\n",
    "grouped_df = groupby(filtered_df_one_two, [:HEURES_MAT, :UNITE, :SOUS_UNITE, :CIRCUIT, :NUMERO, :BR])\n",
    "\n",
    "# Sélectionner les points selon la condition PE = \"E9\" ou sinon PE = \"E8\"\n",
    "selected_rows = DataFrame()\n",
    "\n",
    "for g in grouped_df\n",
    "    if any(row -> row.PE == \"E9\",eachrow(g))\n",
    "        selected_rows = vcat(selected_rows, filter(row -> row.PE == \"E9\", g))\n",
    "    else\n",
    "        selected_rows = vcat(selected_rows, filter(row -> row.PE == \"E8\", g))\n",
    "    end\n",
    "end\n",
    "\n",
    "# Effectuer la jointure\n",
    "joined_df = innerjoin(selected_rows, df_n, on = [:UNITE, :SOUS_UNITE, :CIRCUIT, :NUMERO, :HEURES_MAT])\n",
    "\n",
    "# # # Compter le nombre de lignes dans le résultat de la jointure\n",
    "# nombre_de_points = nrow(joined_df)\n",
    "\n",
    "# # println(\"Le nombre de points est: \", nombre_de_points)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sauvegarder le DataFrame résultant dans un fichier Excel\n",
    "XLSX.openxlsx(\"points_aberrants.xlsx\", mode=\"w\") do xf\n",
    "    sheet = xf[\"Sheet1\"]\n",
    "    \n",
    "    # Écrire les noms de colonnes\n",
    "    for (col_idx, col_name) in enumerate(names(joined_df))\n",
    "        sheet[XLSX.CellRef(1, col_idx)] = col_name\n",
    "    end\n",
    "    \n",
    "    # Écrire les données\n",
    "    row_idx = 2  # Commencer à la ligne 2 pour les données (après les noms de colonnes)\n",
    "    for row in eachrow(joined_df)\n",
    "        for (col_idx, col_name) in enumerate(names(joined_df))\n",
    "            sheet[XLSX.CellRef(row_idx, col_idx)] = row[col_name]\n",
    "        end\n",
    "        row_idx += 1\n",
    "    end\n",
    "end\n",
    "println(\"Le fichier Excel a été sauvegardé\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traitement des fichiers du dossier Encrassement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cette fonction sert à transformer la matrice des données en un objet DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IND_COL_3_and_EncMatToDataFrame (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function IND_COL_3_and_EncMatToDataFrame(mat)\n",
    "    # Extraire les noms des colonnes\n",
    "    column_names = [mat[1,1],\"$(mat[2,3])_ENC\", \"$(mat[2,4])_ENC\", \"$(mat[2,5])_ENC\", \"$(mat[2,6])_ENC\", \"$(mat[2,15])_IND_COL_3\", \"$(mat[2,16])_IND_COL_3\", \"$(mat[2,17])_IND_COL_3\", \"$(mat[2,18])_IND_COL_3\"]\n",
    "\n",
    "    # Créer un DataFrame à partir des données extraites\n",
    "    df1 = DataFrame()\n",
    "    df2 = DataFrame()\n",
    "\n",
    "    # Ajouter les données au DataFrame\n",
    "    df1[!, column_names[1]] = mat[2:end,1]\n",
    "    df1[!, column_names[2]] = mat[2:end,3]\n",
    "    df1[!, column_names[3]] = mat[2:end,4]\n",
    "    df1[!, column_names[4]] = mat[2:end,5]\n",
    "    df1[!, column_names[5]] = mat[2:end,6]\n",
    "\n",
    "    df2[!, column_names[1]] = mat[2:end,1]\n",
    "    df2[!, column_names[6]] = mat[2:end,15]\n",
    "    df2[!, column_names[7]] = mat[2:end,16]\n",
    "    df2[!, column_names[8]] = mat[2:end,17]\n",
    "    df2[!, column_names[9]] = mat[2:end,18]\n",
    "\n",
    "    return df1, df2\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "using XLSX\n",
    "\n",
    "# Spécifiez le chemin complet de votre répertoire\n",
    "directory = \"/home/AD/faidy/JuliaStatsProject/data/raw/real_data/Données_EDF_240611/Encrassement\"\n",
    "\n",
    "# Utilisez readdir() pour obtenir les noms des fichiers et des sous-répertoires\n",
    "files = readdir(directory)\n",
    "\n",
    "# Filtrer les fichiers pour ne garder que ceux qui ont l'extension .xlsx\n",
    "xlsx_files = filter(file -> endswith(file, \".xlsx\"), files)\n",
    "xlsx_files = [file for file in xlsx_files if file != \"~\\$PERFOS_U2S4_3,48-3,47-3,49.xlsx\" && file != \"~\\$PERFOS_U19S2_2,45-2,43-2,44.xlsx\"]\n",
    "# Initialiser un dictionnaire vide pour stocker les DataFrames\n",
    "dict_df_enc = Dict{String, DataFrame}()\n",
    "dict_df_ind_col_3 = Dict{String, DataFrame}()\n",
    "\n",
    "# Lire les fichiers .xlsx et afficher les premières lignes\n",
    "for file in xlsx_files\n",
    "    try\n",
    "        # Lire la première feuille du fichier .xlsx\n",
    "        df_enc, df_ind_col_3 = IND_COL_3_and_EncMatToDataFrame(XLSX.readdata(\"$directory/$file\", \"Feuil1\", \"A1:V1000\"))\n",
    "        dict_df_enc[file] = dropmissing(df_enc, :HEURES_MAT)\n",
    "        dict_df_enc[file] = dropmissing(dict_df_enc[file], :C1_ENC)\n",
    "        dict_df_ind_col_3[file] = dropmissing(df_ind_col_3, :HEURES_MAT)\n",
    "        dict_df_ind_col_3[file] = dropmissing(dict_df_ind_col_3[file], :C1_IND_COL_3)\n",
    "\n",
    "    catch e\n",
    "        display(\"Erreur lors de la lecture du fichier $file: $e\")\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n",
      "(59,)\n"
     ]
    }
   ],
   "source": [
    "println(length(dict_df_enc))\n",
    "println(size(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Premier motif Ux trouvé : U3\n",
      "Premier motif Sy trouvé : S4\n"
     ]
    }
   ],
   "source": [
    "file = \"/home/AD/faidy/JuliaStatsProject/plots/ENC IND-ENC_U3S4_2,61-2,6-2,59.xlsx.png\"\n",
    "\n",
    "# Fonction pour extraire les motifs \"Ux\" et \"Sy\"\n",
    "function extract_UxSy(text::String)\n",
    "    # Initialiser les variables de sortie\n",
    "    Ux = \"\"\n",
    "    Sy = \"\"\n",
    "    \n",
    "    # Trouver le premier motif \"Ux\"\n",
    "    start_idx = findfirst(isequal('U'), text)\n",
    "    if start_idx !== nothing\n",
    "        end_idx = start_idx + 1\n",
    "        while end_idx <= length(text) && isdigit(text[end_idx])\n",
    "            end_idx += 1\n",
    "        end\n",
    "        Ux = text[start_idx:end_idx-1]\n",
    "    end\n",
    "    \n",
    "    # Trouver le motif \"Sy\" après \"Ux\"\n",
    "    if !isempty(Ux)\n",
    "        start_idx = findnext(isequal('S'), text, end_idx)\n",
    "        if start_idx !== nothing\n",
    "            end_idx = start_idx + 1\n",
    "            while end_idx <= length(text) && isdigit(text[end_idx])\n",
    "                end_idx += 1\n",
    "            end\n",
    "            Sy = text[start_idx:end_idx-1]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return Ux, Sy\n",
    "end\n",
    "\n",
    "# Appel de la fonction pour extraire \"Ux\" et \"Sy\" de 'file'\n",
    "Ux, Sy = extract_UxSy(file)\n",
    "\n",
    "# Affichage des résultats\n",
    "println(\"Premier motif Ux trouvé : \", Ux)\n",
    "println(\"Premier motif Sy trouvé : \", Sy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sizes = []\n",
    "\n",
    "for file in xlsx_files\n",
    "    push!(sizes, size(dict_df_enc[file])[2])\n",
    "end\n",
    "\n",
    "sum(sizes) / 56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>257×5 DataFrame</span></div><div style = \"float: right;\"><span style = \"font-style: italic;\">232 rows omitted</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">HEURES_MAT</th><th style = \"text-align: left;\">C1_IND_COL_3</th><th style = \"text-align: left;\">C2_IND_COL_3</th><th style = \"text-align: left;\">C3_IND_COL_3</th><th style = \"text-align: left;\">C4_IND_COL_3</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: left;\">142004.0</td><td style = \"text-align: left;\">83.95</td><td style = \"text-align: left;\">84.15</td><td style = \"text-align: left;\">83.64</td><td style = \"text-align: left;\">83.87</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: left;\">1.42334e5</td><td style = \"text-align: left;\">84.1908</td><td style = \"text-align: left;\">84.3011</td><td style = \"text-align: left;\">83.9153</td><td style = \"text-align: left;\">84.1181</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: left;\">1.4295e5</td><td style = \"text-align: left;\">84.2996</td><td style = \"text-align: left;\">84.301</td><td style = \"text-align: left;\">83.9856</td><td style = \"text-align: left;\">84.1159</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: left;\">1.43721e5</td><td style = \"text-align: left;\">84.08</td><td style = \"text-align: left;\">84.16</td><td style = \"text-align: left;\">83.75</td><td style = \"text-align: left;\">84.01</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: left;\">1.44183e5</td><td style = \"text-align: left;\">84.07</td><td style = \"text-align: left;\">84.16</td><td style = \"text-align: left;\">83.84</td><td style = \"text-align: left;\">83.93</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">6</td><td style = \"text-align: left;\">1.44645e5</td><td style = \"text-align: left;\">84.13</td><td style = \"text-align: left;\">84.17</td><td style = \"text-align: left;\">83.88</td><td style = \"text-align: left;\">83.96</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">7</td><td style = \"text-align: left;\">1.4513e5</td><td style = \"text-align: left;\">84.0416</td><td style = \"text-align: left;\">84.1041</td><td style = \"text-align: left;\">83.8327</td><td style = \"text-align: left;\">83.904</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">8</td><td style = \"text-align: left;\">1.45262e5</td><td style = \"text-align: left;\">84.024</td><td style = \"text-align: left;\">84.061</td><td style = \"text-align: left;\">83.7443</td><td style = \"text-align: left;\">83.8521</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">9</td><td style = \"text-align: left;\">1.45416e5</td><td style = \"text-align: left;\">84.0548</td><td style = \"text-align: left;\">84.0429</td><td style = \"text-align: left;\">83.8179</td><td style = \"text-align: left;\">83.881</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">10</td><td style = \"text-align: left;\">1.45548e5</td><td style = \"text-align: left;\">84.111</td><td style = \"text-align: left;\">84.114</td><td style = \"text-align: left;\">83.8429</td><td style = \"text-align: left;\">83.903</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">11</td><td style = \"text-align: left;\">1.45724e5</td><td style = \"text-align: left;\">84.1271</td><td style = \"text-align: left;\">84.143</td><td style = \"text-align: left;\">83.7924</td><td style = \"text-align: left;\">83.8838</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">12</td><td style = \"text-align: left;\">1.45878e5</td><td style = \"text-align: left;\">84.0525</td><td style = \"text-align: left;\">84.057</td><td style = \"text-align: left;\">83.7594</td><td style = \"text-align: left;\">83.8459</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">13</td><td style = \"text-align: left;\">1.46494e5</td><td style = \"text-align: left;\">83.9867</td><td style = \"text-align: left;\">83.9995</td><td style = \"text-align: left;\">83.6935</td><td style = \"text-align: left;\">83.7443</td></tr><tr><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">246</td><td style = \"text-align: left;\">2.45756e5</td><td style = \"text-align: left;\">84.7032</td><td style = \"text-align: left;\">84.433</td><td style = \"text-align: left;\">84.1383</td><td style = \"text-align: left;\">84.499</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">247</td><td style = \"text-align: left;\">2.46276e5</td><td style = \"text-align: left;\">84.7393</td><td style = \"text-align: left;\">84.4259</td><td style = \"text-align: left;\">84.2787</td><td style = \"text-align: left;\">84.7295</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">248</td><td style = \"text-align: left;\">2.46797e5</td><td style = \"text-align: left;\">84.822</td><td style = \"text-align: left;\">84.4843</td><td style = \"text-align: left;\">84.3892</td><td style = \"text-align: left;\">84.7773</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">249</td><td style = \"text-align: left;\">2.47057e5</td><td style = \"text-align: left;\">84.9267</td><td style = \"text-align: left;\">84.6117</td><td style = \"text-align: left;\">84.4803</td><td style = \"text-align: left;\">84.869</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">250</td><td style = \"text-align: left;\">248359.0</td><td style = \"text-align: left;\">84.7985</td><td style = \"text-align: left;\">84.5507</td><td style = \"text-align: left;\">84.4578</td><td style = \"text-align: left;\">84.776</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">251</td><td style = \"text-align: left;\">2.4888e5</td><td style = \"text-align: left;\">84.7527</td><td style = \"text-align: left;\">84.5172</td><td style = \"text-align: left;\">84.403</td><td style = \"text-align: left;\">84.6463</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">252</td><td style = \"text-align: left;\">2.494e5</td><td style = \"text-align: left;\">84.7713</td><td style = \"text-align: left;\">84.5673</td><td style = \"text-align: left;\">84.3168</td><td style = \"text-align: left;\">84.6693</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">253</td><td style = \"text-align: left;\">2.49921e5</td><td style = \"text-align: left;\">84.8706</td><td style = \"text-align: left;\">84.589</td><td style = \"text-align: left;\">84.4118</td><td style = \"text-align: left;\">84.6684</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">254</td><td style = \"text-align: left;\">2.50442e5</td><td style = \"text-align: left;\">84.4</td><td style = \"text-align: left;\">84.4286</td><td style = \"text-align: left;\">84.6</td><td style = \"text-align: left;\">84.5561</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">255</td><td style = \"text-align: left;\">2.50962e5</td><td style = \"text-align: left;\">84.8449</td><td style = \"text-align: left;\">84.6135</td><td style = \"text-align: left;\">84.4143</td><td style = \"text-align: left;\">84.7231</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">256</td><td style = \"text-align: left;\">2.51483e5</td><td style = \"text-align: left;\">84.6842</td><td style = \"text-align: left;\">84.383</td><td style = \"text-align: left;\">84.1772</td><td style = \"text-align: left;\">84.4933</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">257</td><td style = \"text-align: left;\">2.51892e5</td><td style = \"text-align: left;\">84.7102</td><td style = \"text-align: left;\">84.4032</td><td style = \"text-align: left;\">84.2062</td><td style = \"text-align: left;\">84.5362</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccc}\n",
       "\t& HEURES\\_MAT & C1\\_IND\\_COL\\_3 & C2\\_IND\\_COL\\_3 & C3\\_IND\\_COL\\_3 & C4\\_IND\\_COL\\_3\\\\\n",
       "\t\\hline\n",
       "\t& Any & Any & Any & Any & Any\\\\\n",
       "\t\\hline\n",
       "\t1 & 142004.0 & 83.95 & 84.15 & 83.64 & 83.87 \\\\\n",
       "\t2 & 1.42334e5 & 84.1908 & 84.3011 & 83.9153 & 84.1181 \\\\\n",
       "\t3 & 1.4295e5 & 84.2996 & 84.301 & 83.9856 & 84.1159 \\\\\n",
       "\t4 & 1.43721e5 & 84.08 & 84.16 & 83.75 & 84.01 \\\\\n",
       "\t5 & 1.44183e5 & 84.07 & 84.16 & 83.84 & 83.93 \\\\\n",
       "\t6 & 1.44645e5 & 84.13 & 84.17 & 83.88 & 83.96 \\\\\n",
       "\t7 & 1.4513e5 & 84.0416 & 84.1041 & 83.8327 & 83.904 \\\\\n",
       "\t8 & 1.45262e5 & 84.024 & 84.061 & 83.7443 & 83.8521 \\\\\n",
       "\t9 & 1.45416e5 & 84.0548 & 84.0429 & 83.8179 & 83.881 \\\\\n",
       "\t10 & 1.45548e5 & 84.111 & 84.114 & 83.8429 & 83.903 \\\\\n",
       "\t11 & 1.45724e5 & 84.1271 & 84.143 & 83.7924 & 83.8838 \\\\\n",
       "\t12 & 1.45878e5 & 84.0525 & 84.057 & 83.7594 & 83.8459 \\\\\n",
       "\t13 & 1.46494e5 & 83.9867 & 83.9995 & 83.6935 & 83.7443 \\\\\n",
       "\t14 & 1.4667e5 & 84.1798 & 84.1435 & 83.7852 & 83.889 \\\\\n",
       "\t15 & 1.50368e5 & 84.193 & 84.2197 & 83.9437 & 83.6459 \\\\\n",
       "\t16 & 1.50525e5 & 84.2427 & 84.2886 & 83.9757 & 83.7065 \\\\\n",
       "\t17 & 150642.0 & 84.096 & 84.1603 & 83.7787 & 83.537 \\\\\n",
       "\t18 & 1.50799e5 & 84.0684 & 84.1371 & 83.7848 & 83.5435 \\\\\n",
       "\t19 & 151092.0 & 84.2573 & 84.2517 & 83.9167 & 83.633 \\\\\n",
       "\t20 & 1.51346e5 & 83.7549 & 83.9748 & 83.4514 & 83.1951 \\\\\n",
       "\t21 & 1.51464e5 & 83.6746 & 83.9651 & 83.3723 & 83.1545 \\\\\n",
       "\t22 & 1.5164e5 & 83.6646 & 83.9003 & 83.3913 & 83.1117 \\\\\n",
       "\t23 & 1.51757e5 & 83.6292 & 83.8403 & 83.3148 & 83.1103 \\\\\n",
       "\t24 & 1.51894e5 & 83.6605 & 83.8703 & 83.3284 & 83.1216 \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m257×5 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m HEURES_MAT \u001b[0m\u001b[1m C1_IND_COL_3 \u001b[0m\u001b[1m C2_IND_COL_3 \u001b[0m\u001b[1m C3_IND_COL_3 \u001b[0m\u001b[1m C4_IND_COL_3 \u001b[0m\n",
       "     │\u001b[90m Any        \u001b[0m\u001b[90m Any          \u001b[0m\u001b[90m Any          \u001b[0m\u001b[90m Any          \u001b[0m\u001b[90m Any          \u001b[0m\n",
       "─────┼────────────────────────────────────────────────────────────────────\n",
       "   1 │ 142004.0    83.95         84.15         83.64         83.87\n",
       "   2 │ 1.42334e5   84.1908       84.3011       83.9153       84.1181\n",
       "   3 │ 1.4295e5    84.2996       84.301        83.9856       84.1159\n",
       "   4 │ 1.43721e5   84.08         84.16         83.75         84.01\n",
       "   5 │ 1.44183e5   84.07         84.16         83.84         83.93\n",
       "   6 │ 1.44645e5   84.13         84.17         83.88         83.96\n",
       "   7 │ 1.4513e5    84.0416       84.1041       83.8327       83.904\n",
       "   8 │ 1.45262e5   84.024        84.061        83.7443       83.8521\n",
       "  ⋮  │     ⋮            ⋮             ⋮             ⋮             ⋮\n",
       " 251 │ 2.4888e5    84.7527       84.5172       84.403        84.6463\n",
       " 252 │ 2.494e5     84.7713       84.5673       84.3168       84.6693\n",
       " 253 │ 2.49921e5   84.8706       84.589        84.4118       84.6684\n",
       " 254 │ 2.50442e5   84.4          84.4286       84.6          84.5561\n",
       " 255 │ 2.50962e5   84.8449       84.6135       84.4143       84.7231\n",
       " 256 │ 2.51483e5   84.6842       84.383        84.1772       84.4933\n",
       " 257 │ 2.51892e5   84.7102       84.4032       84.2062       84.5362\n",
       "\u001b[36m                                                          242 rows omitted\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dict_df_ind_col_3[\"IND-ENC_U4S2_1,43-1,42-1,36-1,41.xlsx\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for file in xlsx_files\n",
    "\n",
    "\n",
    "    p = plot(dict_df_enc[file].HEURES_MAT, dict_df_enc[file].C1_ENC, xlabel=\"HEURES_MAT\", ylabel=\"VALEUR\", label=\"C1\", legend=:topright, markershape=:circle, markercolor=:blue, linestyle=:dash)\n",
    "    plot!(p, dict_df_enc[file].HEURES_MAT, dict_df_enc[file].C2_ENC, xlabel=\"HEURES_MAT\", ylabel=\"VALEUR\", label=\"C2\", legend=:topright,  markershape=:circle, markercolor=:red, linestyle=:dash)\n",
    "    plot!(p, dict_df_enc[file].HEURES_MAT, dict_df_enc[file].C3_ENC, xlabel=\"HEURES_MAT\", ylabel=\"VALEUR\", label=\"C3\", legend=:topright,  markershape=:circle, markercolor=:purple, linestyle=:dash)\n",
    "    if !ismissing(unique(dict_df_enc[file].C4_ENC)[1] )\n",
    "        plot!(p, dict_df_enc[file].HEURES_MAT, dict_df_enc[file].C4_ENC, xlabel=\"HEURES_MAT\", ylabel=\"VALEUR\", label=\"C4\", legend=:topright,  markershape=:circle, markercolor=:gray, linestyle=:dash)\n",
    "    end\n",
    "\n",
    "    unite, sous_unite = extract_UxSy(file)\n",
    "    \n",
    "    heures_nettoyages = filter(raw -> raw.UNITE .== unite && raw.SOUS_UNITE .== sous_unite, df_nettoyages)\n",
    "    vline!(p, heures_nettoyages.HEURES_MAT, linestyle=:dot, color=:black, linewidth=1.5, label=false)\n",
    "\n",
    "\n",
    "    # Chemin du répertoire où vous souhaitez enregistrer le fichier (relatif au répertoire de travail actuel)\n",
    "    directory = \"/home/AD/faidy/JuliaStatsProject/plots/ENC\"\n",
    "\n",
    "    # Combiner le chemin de répertoire et le nom du fichier\n",
    "    filename = joinpath(directory, \"$file.png\")\n",
    "\n",
    "    # Sauvegarder le graphique dans le fichier spécifié\n",
    "    savefig(p, filename)\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in xlsx_files\n",
    "    p = plot(dict_df_ind_col_3[file].HEURES_MAT, dict_df_ind_col_3[file].C1_IND_COL_3, xlabel=\"HEURES_MAT\", ylabel=\"VALEUR\", label=\"C1\", legend=:topright, markershape=:circle, markercolor=:blue, linestyle=:dash)\n",
    "    plot!(p, dict_df_ind_col_3[file].HEURES_MAT, dict_df_ind_col_3[file].C2_IND_COL_3, xlabel=\"HEURES_MAT\", ylabel=\"VALEUR\", label=\"C2\", legend=:topright,  markershape=:circle, markercolor=:red, linestyle=:dash)\n",
    "    plot!(p, dict_df_ind_col_3[file].HEURES_MAT, dict_df_ind_col_3[file].C3_IND_COL_3, xlabel=\"HEURES_MAT\", ylabel=\"VALEUR\", label=\"C3\", legend=:topright,  markershape=:circle, markercolor=:purple, linestyle=:dash)\n",
    "    if !ismissing(unique(dict_df_ind_col_3[file].C4_IND_COL_3)[1] )\n",
    "        plot!(p, dict_df_ind_col_3[file].HEURES_MAT, dict_df_ind_col_3[file].C3_IND_COL_3, xlabel=\"HEURES_MAT\", ylabel=\"VALEUR\", label=\"C4\", legend=:topright,  markershape=:circle, markercolor=:gray, linestyle=:dash)\n",
    "    end\n",
    "    \n",
    "    unite, sous_unite = extract_UxSy(file)\n",
    "    \n",
    "    heures_nettoyages = filter(raw -> raw.UNITE .== unite && raw.SOUS_UNITE .== sous_unite, df_nettoyages)\n",
    "    vline!(p, heures_nettoyages.HEURES_MAT, linestyle=:dot, color=:black, linewidth=1.5, label=false)\n",
    "\n",
    "\n",
    "    # Chemin du répertoire où vous souhaitez enregistrer le fichier (relatif au répertoire de travail actuel)\n",
    "    directory = \"/home/AD/faidy/JuliaStatsProject/plots/IND_COL_3\"\n",
    "\n",
    "    # Combiner le chemin de répertoire et le nom du fichier\n",
    "    filename = joinpath(directory, \"$file.png\")\n",
    "\n",
    "    # Sauvegarder le graphique dans le fichier spécifié\n",
    "    savefig(p, filename)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nettoyages = readxlsheet(\"/home/AD/faidy/JuliaStatsProject/data/raw/real_data/Données_EDF_240611/Nettoyages/NETTOYAGES.xls\", \"NETTOYAGES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nettoyages = MatrixToDataFrame(nettoyages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nettoyages = df_nettoyages[:, [:UNITE, :SOUS_UNITE, :CIRCUIT, :NUMERO, :HEURES_MAT]]\n",
    "df_nettoyages = rename!(df_nettoyages, :HEURES_MAT => :HEURES_NETT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_one_two_with_nett = leftjoin(df_one_two[:, [:UNITE, :SOUS_UNITE, :CIRCUIT, :NUMERO, :HEURES_MAT]], df_nettoyages, on = [:UNITE, :SOUS_UNITE, :CIRCUIT, :NUMERO] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unites = unique(df_one_two.UNITE)\n",
    "sizes_between_nett_col1 = []\n",
    "sizes_between_nett_col2 = []\n",
    "sizes_on_nett_col1 = []\n",
    "sizes_on_nett_col2 = []\n",
    "for unite in unites\n",
    "    unite_data = df_one_two[df_one_two.UNITE .== unite,:]\n",
    "    sous_unites = unique(unite_data.SOUS_UNITE)\n",
    "    for sous_unite in sous_unites\n",
    "        sous_unite_data = unite_data[unite_data.SOUS_UNITE .== sous_unite,:]\n",
    "        circuits = unique(sous_unite_data.CIRCUIT)\n",
    "        for circuit in circuits\n",
    "            \n",
    "            heures_nettoyages = filter(raw -> raw.UNITE .== unite && raw.SOUS_UNITE .== sous_unite && raw.CIRCUIT .== circuit, df_nettoyages)\n",
    "            \n",
    "            if !isempty(heures_nettoyages)\n",
    "                circuit_data = filter(row -> row.PE .== \"E9\" && row.BR .== \"C\", sous_unite_data[sous_unite_data.CIRCUIT .== circuit,:])\n",
    "                sort!(heures_nettoyages, :HEURES_NETT)\n",
    "\n",
    "                if !isempty(circuit_data)\n",
    "                    ind_col_1 = circuit_data[ismissing.(circuit_data.SONDE),:]\n",
    "                    ind_col_2 = circuit_data[.!ismissing.(circuit_data.SONDE),:]\n",
    "                    if !isempty(ind_col_1)    \n",
    "                        # Compter les points de `circuit_data` dont `HEURES_MAT` est dans l'intervalle [start_time, end_time)\n",
    "                        for i in 1:(nrow(heures_nettoyages) - 1)\n",
    "                            start_time = heures_nettoyages.HEURES_NETT[i]\n",
    "                            end_time = heures_nettoyages.HEURES_NETT[i + 1]\n",
    "                            \n",
    "                            count_points1 = count(row -> start_time < row < end_time, ind_col_1.HEURES_MAT)\n",
    "                            count_points3 = count(row -> start_time == row , ind_col_1.HEURES_MAT)\n",
    "                            # Ajouter le nombre de points à `points_counts`\n",
    "                            push!(sizes_between_nett_col1, count_points1)\n",
    "                            push!(sizes_on_nett_col1, count_points3)\n",
    "                        end\n",
    "                    end\n",
    "                    if !isempty(ind_col_2)\n",
    "                        for i in 1:(nrow(heures_nettoyages) - 1)\n",
    "                            start_time = heures_nettoyages.HEURES_NETT[i]\n",
    "                            end_time = heures_nettoyages.HEURES_NETT[i + 1]\n",
    "                            \n",
    "                            count_points2 = count(row -> start_time < row < end_time, ind_col_2.HEURES_MAT)\n",
    "                            count_points3 = count(row -> start_time == row , ind_col_2.HEURES_MAT)\n",
    "                            # Ajouter le nombre de points à `points_counts`\n",
    "                            push!(sizes_between_nett_col2, count_points2)\n",
    "                            push!(sizes_on_nett_col2, count_points3)\n",
    "                        end\n",
    "                    end\n",
    "                else\n",
    "                    circuit_data = filter(row -> row.PE .== \"E8\" && row.BR .== \"C\", sous_unite_data[sous_unite_data.CIRCUIT .== circuit,:])\n",
    "                    ind_col_1 = circuit_data[ismissing.(circuit_data.SONDE),:]\n",
    "                    ind_col_2 = circuit_data[.!ismissing.(circuit_data.SONDE),:]\n",
    "                    \n",
    "                    if !isempty(ind_col_1)    \n",
    "                        # Compter les points de `circuit_data` dont `HEURES_MAT` est dans l'intervalle [start_time, end_time)\n",
    "                        for i in 1:(nrow(heures_nettoyages) - 1)\n",
    "                            start_time = heures_nettoyages.HEURES_NETT[i]\n",
    "                            end_time = heures_nettoyages.HEURES_NETT[i + 1]\n",
    "                            \n",
    "                            count_points1 = count(row -> start_time < row < end_time, ind_col_1.HEURES_MAT)\n",
    "                            count_points3 = count(row -> start_time == row , ind_col_1.HEURES_MAT)\n",
    "                            # Ajouter le nombre de points à `points_counts`\n",
    "                            push!(sizes_between_nett_col1, count_points1)\n",
    "                            push!(sizes_on_nett_col1, count_points3)\n",
    "                        end\n",
    "                    end\n",
    "                    if !isempty(ind_col_2)\n",
    "                        for i in 1:(nrow(heures_nettoyages) - 1)\n",
    "                            start_time = heures_nettoyages.HEURES_NETT[i]\n",
    "                            end_time = heures_nettoyages.HEURES_NETT[i + 1]\n",
    "                            \n",
    "                            count_points2 = count(row -> start_time < row < end_time, ind_col_2.HEURES_MAT)\n",
    "                            count_points3 = count(row -> start_time == row , ind_col_2.HEURES_MAT)\n",
    "                            # Ajouter le nombre de points à `points_counts`\n",
    "                            push!(sizes_between_nett_col2, count_points2)\n",
    "                            push!(sizes_on_nett_col2, count_points3)\n",
    "                        end\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heures_nettoyages = filter(raw -> raw.UNITE .== \"U4\" && raw.SOUS_UNITE .== \"S2\" && raw.CIRCUIT .== \"C3\", df_nettoyages)\n",
    "collect(1:0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length(sizes_between_nett_col1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length(sizes_between_nett_col2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length(sizes_on_nett_col1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram(sizes_between_nett_col1, bins=7, title=\"\", xlabel=\"Taille\", ylabel=\"Fréquence\", label=\"Fréquence\", titlefontsize=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram(sizes_between_nett_col2, bins=6, title=\"\", xlabel=\"Taille\", ylabel=\"Fréquence\", label=\"Fréquence\", titlefontsize=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_frequency = mean(sizes_on_nett_col1)\n",
    "display(average_frequency)\n",
    "histogram(sizes_on_nett_col1, bins=6, title=\"\", xlabel=\"Taille\", ylabel=\"Fréquence\", label=\"Fréquence\", titlefontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_frequency = mean(sizes_on_nett_col2)\n",
    "display(average_frequency)\n",
    "histogram(sizes_on_nett_col2, bins=6, title=\"\", xlabel=\"Taille\", ylabel=\"Fréquence\", label=\"Fréquence\", titlefontsize=10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.4",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
